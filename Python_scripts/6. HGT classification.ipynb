{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "91e53f74",
   "metadata": {},
   "source": [
    "## Description  \n",
    "In this notebook, we analyze the processed and recomputed trees to classify them into three classes: vertical evolution, unsupported HGT, supported HGT.      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "35dc82cb",
   "metadata": {},
   "outputs": [],
   "source": [
    "%matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c83de561",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from path import Path\n",
    "from ete3 import Tree\n",
    "from Bio import SeqIO\n",
    "import ete3\n",
    "from ete3 import Tree, NCBITaxa\n",
    "import re\n",
    "from path import Path\n",
    "from warnings import warn\n",
    "from collections import Counter\n",
    "import os\n",
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "from collections import defaultdict\n",
    "from hgt_algorithms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58124ed1",
   "metadata": {},
   "outputs": [],
   "source": [
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dacd85d9",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e17e70e6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_directory = Path('third_round_trees')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b21bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tree_dir = Path('final_processed_trees') "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4f312645",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid_table = open('final_homolog_taxid_table')\n",
    "taxid_table = {l.strip().split()[0]: l.strip().split()[1] for l in taxid_table if l.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b8c061f",
   "metadata": {},
   "outputs": [],
   "source": [
    "fungi_taxid = 4751\n",
    "bacteria_taxid = 2\n",
    "animal_taxid = 33208"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88eddb9c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_accessions = open('basal_accessions.txt')\n",
    "target_accessions = set(l.strip() for l in target_accessions if l.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "659d523f",
   "metadata": {},
   "source": [
    "## Tree processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "636ccf00",
   "metadata": {},
   "outputs": [],
   "source": [
    "hgt_data = [['cluster_id', \n",
    "             'hgt_criterion',\n",
    "             'well_supported',\n",
    "             'fungal_LCA',\n",
    "             'gene_origin',\n",
    "             'sister1_LCA',\n",
    "             'sister2_LCA',\n",
    "             'joint_sister_LCA',\n",
    "             'fungal_accessions',\n",
    "             'gene_tree_leaves',\n",
    "             'fungal_species_nb', \n",
    "             'all_species_nb', \n",
    "             'split_distance',\n",
    "             'repositionable',\n",
    "             'fungal_clade_support',\n",
    "             'average adjacent branch support',\n",
    "             'fungal_branch_length']]\n",
    "\n",
    "tree_files = [f for f in os.listdir(tree_directory) if f[-8:] == 'treefile' ]\n",
    "nb_of_files = len(tree_files)\n",
    "print(nb_of_files, 'trees to process')\n",
    "\n",
    "nb_of_all_trees = 0\n",
    "ORFan_trees = 0\n",
    "purely_fungal_trees = 0\n",
    "no_target_proteins = 0\n",
    "\n",
    "all_branch_lengths = []\n",
    "fg_clade_branch_lengths = [] \n",
    "tree_sizes = []\n",
    "\n",
    "for file_id, filename in enumerate(tree_files):\n",
    "    if not file_id % 10:\n",
    "        print(file_id, 'out of', nb_of_files)\n",
    "    cluster_accession = '.'.join(filename.split('.')[:-1])\n",
    "    \n",
    "    \n",
    "    hgt_criterion = ''    \n",
    "    bdi = ''\n",
    "    repositionable = ''\n",
    "    sister1_lca = ''\n",
    "    sister2_lca = ''\n",
    "    joint_lca = ''\n",
    "    fungal_lca = ''\n",
    "    well_supported = ''\n",
    "    gene_origin = ''\n",
    "    fg_support = ''\n",
    "    fungal_branch_length = -1\n",
    "    average_posthgt_substitution = -1  # average length from fungal leaves to root of fungal clade\n",
    "    \n",
    "    \n",
    "    G = Tree(tree_directory / filename, format=1) \n",
    "    nb_of_all_trees += 1\n",
    "    for i, n in enumerate(G.traverse('postorder')):\n",
    "        if n.is_leaf():\n",
    "            n.support = 100.  # by definition\n",
    "        elif not n.is_root():\n",
    "            if n.name:\n",
    "                n.support = float(n.name)\n",
    "            else:\n",
    "                n.support = 100  # IQTree doesn't assign support values for identical proteins \n",
    "                \n",
    "#            # Version for two types of branch support from IQTree (Ultrafast Bootstrap + SH-aLRT):\n",
    "#             assert not n.name or len(n.name.split('/')) == 2\n",
    "#             if len(n.name.split('/')) == 2:\n",
    "#                 n.support = float(n.name.split('/')[1])\n",
    "#                 n.name = '' \n",
    "#             else:\n",
    "#                 n.support = 0\n",
    "            \n",
    "    G.set_outgroup(G.get_midpoint_outgroup())\n",
    "    all_branch_lengths.append([n.dist for n in G.traverse() if not n.is_root()])\n",
    "    \n",
    "    # Labelling internal nodes:\n",
    "    for i, n in enumerate(G.traverse('postorder')):\n",
    "        if not n.is_leaf():\n",
    "            n.name = 'node%i' % i\n",
    "            \n",
    "    # Get taxonomic information\n",
    "    protein_accessions = {l.name for l in G}\n",
    "    accession_to_taxid = {acc: taxid_table[acc] for acc in protein_accessions}\n",
    "    all_species = set(accession_to_taxid.values())\n",
    "    if len(all_species) < 4:\n",
    "        ORFan_trees += 1\n",
    "        continue\n",
    "    lineages = {tx: ncbi.get_lineage(tx) for tx in all_species} # note: lineages coded in integers here\n",
    "    fungal_taxids = {tx for tx in all_species if fungi_taxid in lineages[tx]} # note: taxids coded in strings here \n",
    "    fungal_proteins = {acc for acc in protein_accessions if taxid_table[acc] in fungal_taxids}\n",
    "    target_proteins = fungal_proteins.intersection(target_accessions)\n",
    "    \n",
    "    if not target_proteins:\n",
    "        no_target_proteins += 1\n",
    "        continue\n",
    "    if len(fungal_taxids) >= len(all_species) - 1:\n",
    "        purely_fungal_trees += 1\n",
    "        continue\n",
    "        \n",
    "    # Identify displaced clades\n",
    "    S = ncbi.get_topology(all_species, intermediate_nodes=False)\n",
    "    UG = UnrootedForest(G)\n",
    "    US = UnrootedForest(S, binary=False)\n",
    "    fungal_cdis = UG.get_clade_displacements(fungal_proteins, US, accession_to_taxid)\n",
    "    assert fungal_cdis,'Fungal clades not found'\n",
    "    # Identify if correct placement of fungal clade exists in G\n",
    "    # This can be done once for all fungal clades\n",
    "    predicted_fungal_clade_location = UG.get_optimal_clade_location(fungal_proteins, US, accession_to_taxid)\n",
    "    min_cdi_in_G = predicted_fungal_clade_location[1]\n",
    "    \n",
    "    \n",
    "    # Check each identified clade for other HGT criteria\n",
    "    # Check supports and branch lengths\n",
    "    for clade_edge, cdi in fungal_cdis:\n",
    "        adjacent_nodes = UG.get_neighbours(clade_edge[0])\n",
    "        adjacent_edges = [frozenset((clade_edge[0], adj_node)) for adj_node in adjacent_nodes]\n",
    "        assert len(adjacent_edges) == 3\n",
    "        supports = [UG.edge_supports[edge] for edge in adjacent_edges]\n",
    "        average_support = sum(supports)/3.\n",
    "        fungal_branch_length = UG.edge_lengths[frozenset(clade_edge)]\n",
    "        fungal_branch_support = UG.edge_supports[frozenset(clade_edge)]\n",
    "        fg_clade_branch_lengths.append(fungal_branch_length)\n",
    "        if cdi > 0:\n",
    "            cluster_type = 'hgt' \n",
    "        else:\n",
    "            cluster_type = 'homoplasy'\n",
    "        # Get gene origin\n",
    "        neighbour_clade_leaves = [UG.get_clade_leaves((clade_edge[0], adj_node)) for adj_node in adjacent_nodes if adj_node != clade_edge[1]]\n",
    "        assert len(neighbour_clade_leaves) == 2, 'Improper number of neighbours'\n",
    "        # mask other fungal proteins\n",
    "        neighbour_clade_leaves = [[leaf_name for leaf_name in clade if leaf_name not in fungal_proteins] for clade in neighbour_clade_leaves]\n",
    "        neighbour_clade_species = [set(accession_to_taxid[leaf_name] for leaf_name in clade) for clade in neighbour_clade_leaves]\n",
    "        all_neighbour_species = neighbour_clade_species[0] | neighbour_clade_species[1]\n",
    "        sister1_lca = ncbi.get_topology(neighbour_clade_species[0]).taxid\n",
    "        sister2_lca = ncbi.get_topology(neighbour_clade_species[1]).taxid\n",
    "        joint_neighbour_lca = ncbi.get_topology(all_neighbour_species).taxid\n",
    "        fungal_clade_leaves = UG.get_clade_leaves(clade_edge)\n",
    "        fungal_species = set([accession_to_taxid[leaf_name] for leaf_name in fungal_clade_leaves])\n",
    "        fungal_lca = ncbi.get_topology(fungal_species).taxid\n",
    "        if cdi == 0:\n",
    "            gene_origin = 'N/A'\n",
    "        elif sister1_lca == sister2_lca:\n",
    "            assert sister1_lca == joint_neighbour_lca\n",
    "            gene_origin = joint_neighbour_lca\n",
    "        elif sister1_lca == joint_neighbour_lca:\n",
    "            gene_origin = sister2_lca\n",
    "        elif sister2_lca == joint_neighbour_lca:\n",
    "            gene_origin = sister1_lca\n",
    "        else:\n",
    "            gene_origin = 'Undetermined'\n",
    "        \n",
    "        highly_certain = cluster_type == 'hgt' and average_support >= 90 and min_cdi_in_G == 0 and gene_origin!='Undetermined'\n",
    "        highly_certain = 'Yes' if highly_certain else 'No'\n",
    "        assert cluster_accession and cluster_type and highly_certain and fungal_lca and \\\n",
    "                gene_origin and sister1_lca and sister2_lca and joint_neighbour_lca\n",
    "        hgt_data.append([cluster_accession, \n",
    "                         cluster_type,\n",
    "                         highly_certain,\n",
    "                         fungal_lca,\n",
    "                         gene_origin,\n",
    "                         sister1_lca,\n",
    "                         sister2_lca,\n",
    "                         joint_neighbour_lca,\n",
    "                         '\"' + ','.join(fungal_clade_leaves) + '\"',  # Note: accessions of duplicated sequences happen here \n",
    "                         len(G),                                     # due to new proteome releases, but this is needed for \n",
    "                         len(fungal_species),                        # xenolog analyses to get clades\n",
    "                         len(all_species), \n",
    "                         cdi,\n",
    "                         min_cdi_in_G,\n",
    "                         fungal_branch_support, \n",
    "                         average_support,\n",
    "                         fungal_branch_length])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf6547d3",
   "metadata": {},
   "source": [
    "Diagnostic information:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee5a7c3c",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "print(file_id, filename)\n",
    "print(G.get_ascii(attributes=['name', 'support']))\n",
    "print(S.get_ascii(attributes=['sci_name', 'taxid']))\n",
    "print(fungal_cdis)\n",
    "print(predicted_fungal_clade_location)\n",
    "print(supports)\n",
    "print(fungal_branch_length)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "acf07334",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Processing results:')\n",
    "\n",
    "print('All trees:', nb_of_all_trees)\n",
    "print('All fungal clades:', len(hgt_data) - 1)\n",
    "#print('Trees with fungi:', nb_of_trees_with_any_fungus)\n",
    "#print('Trees with fungal and non-fungal species:', nb_of_trees_with_mixed_species)\n",
    "#print('Trees with monophyletic EDF fungi in mixed-species trees:', nb_of_trees_with_monophyletic_edf_fungi)\n",
    "print('Number of trees with >300 leaves:', sum(x>300 for x in tree_sizes))\n",
    "#print('Trees without target proteins:', no_target_proteins)\n",
    "\n",
    "print('Nb of HGT candidates:')\n",
    "print(len(hgt_data)-1)\n",
    "print('Nb of HGT clades per criterion:')\n",
    "for cr in set(l[1] for l in hgt_data[1:]):\n",
    "    print(cr, sum(l[1]==cr for l in hgt_data))\n",
    "print('Nb of HGT trees per criterion:')\n",
    "for cr in set(l[1] for l in hgt_data[1:]):\n",
    "    print(cr, len(set([l[0] for l in hgt_data if l[1] == cr])))\n",
    "print('Nb of fungal transferred proteins with weah support:', sum(len(l[8].split(',')) for l in hgt_data[1:] if l[1] == 'hgt'))\n",
    "print('Nb of EDF transferred proteins with weak support:', sum(len(set(l[8].split(',')) & target_accessions) for l in hgt_data[1:] if l[1] == 'hgt'))\n",
    "print('Number of well supported transfers:', sum(x[2] ==  'Yes' for x in hgt_data))\n",
    "print('Number of trees with a well-supported transfer:', len(set(x[0] for x in hgt_data if x[2] == 'Yes')))\n",
    "print('Proportion of well-supported transfers among displaced clade transfers:', round(sum(x[2] == 'Yes' for x in hgt_data)/sum(l[1]=='hgt' for l in hgt_data), 2))\n",
    "# print('Number of well supported transfers with SH support > 85:', sum(x[2] == 'Yes' and x[15] > 85 for x in hgt_data))\n",
    "print('Nb of well-supported fungal xenologs:', sum(len(l[8].split(',')) for l in hgt_data[1:] if l[2] == 'Yes'))\n",
    "print('Nb of well-supported target xenologs:', sum(len(target_accessions.intersection(l[8].replace('\"', '').split(','))) for l in hgt_data[1:] if l[2] == 'Yes'))\n",
    "print('Nb of fungal proteins with homoplasy:', sum(len(l[8].replace('\"', '').split(',')) for l in hgt_data[1:] if l[1] == 'homoplasy'))\n",
    "print('Nb of EDF proteins with homoplasy:', sum(len(target_accessions.intersection(l[8].replace('\"', '').split(','))) for l in hgt_data[1:] if l[1] == 'homoplasy'))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "677795f3",
   "metadata": {},
   "source": [
    "**Saving the result table:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e1f39920",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('hgt_results.tsv', 'w') as h:\n",
    "    h.write('\\n'.join('\\t'.join(map(str, l)) for l in hgt_data) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b45707b8",
   "metadata": {},
   "source": [
    "**Relabeling and saving the trees:**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "376b21ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(final_tree_dir)\n",
    "except FileExistsError:\n",
    "    pass\n",
    "try:\n",
    "    os.mkdir(final_tree_dir / 'supported_hgt')\n",
    "except FileExistsError:\n",
    "    dir_contents = os.listdir(final_tree_dir / 'supported_hgt')\n",
    "    for f in dir_contents:\n",
    "        os.remove(final_tree_dir / 'supported_hgt' / f)\n",
    "try:\n",
    "    os.mkdir(final_tree_dir / 'unsupported_hgt')\n",
    "except FileExistsError:\n",
    "    dir_contents = os.listdir(final_tree_dir / 'unsupported_hgt')\n",
    "    for f in dir_contents:\n",
    "        os.remove(final_tree_dir / 'unsupported_hgt' / f)\n",
    "try:\n",
    "    os.mkdir(final_tree_dir / 'homoplasy')\n",
    "except FileExistsError:\n",
    "    dir_contents = os.listdir(final_tree_dir / 'homoplasy')\n",
    "    for f in dir_contents:\n",
    "        os.remove(final_tree_dir / 'homoplasy' / f)\n",
    "try:\n",
    "    os.mkdir(final_tree_dir / 'identity')\n",
    "except FileExistsError:\n",
    "    dir_contents = os.listdir(final_tree_dir / 'identity')\n",
    "    for f in dir_contents:\n",
    "        os.remove(final_tree_dir / 'identity' / f)\n",
    "        \n",
    "for hgt in hgt_data[1:]:\n",
    "    T = Tree(tree_directory / hgt[0] + '.treefile', format=1)\n",
    "    taxids = {l.name : int(taxid_table[l.name]) for l in T}\n",
    "    sci_names = ncbi.get_taxid_translator(list(taxids.values()))\n",
    "    S = ncbi.get_topology(set(taxids.values()), intermediate_nodes=False)\n",
    "    for l in T:\n",
    "        l.accession = l.name\n",
    "        l.taxid = taxids[l.name]\n",
    "        l.name = sci_names[taxids[l.name]].replace(' ', '_')\n",
    "    for l in S:\n",
    "        l.name = sci_names[int(l.name)].replace(' ', '_')\n",
    "    if hgt[2] == 'Yes':\n",
    "        T.write(outfile = final_tree_dir / 'supported_hgt' / hgt[0] + '.genetree', \n",
    "                features=['accession', 'taxid'], format_root_node=False, format=1)\n",
    "        S.write(outfile = final_tree_dir / 'supported_hgt' / hgt[0] + '.speciestree', \n",
    "                format_root_node=False, format=9)\n",
    "    elif hgt[1] == 'hgt':\n",
    "        T.write(outfile = final_tree_dir / 'unsupported_hgt' / hgt[0] + '.genetree', \n",
    "                features=['accession', 'taxid'], format_root_node=False, format=1)\n",
    "        S.write(outfile = final_tree_dir / 'unsupported_hgt' / hgt[0] + '.speciestree', \n",
    "                format_root_node=False, format=9)\n",
    "    elif hgt[1] == 'homoplasy':\n",
    "        T.write(outfile = final_tree_dir / 'homoplasy' / hgt[0] + '.genetree', \n",
    "                features=['accession', 'taxid'], format_root_node=False, format=1)\n",
    "        S.write(outfile = final_tree_dir / 'homoplasy' / hgt[0] + '.speciestree', \n",
    "                format_root_node=False, format=9)\n",
    "    elif hgt[1] == 'identity':\n",
    "        T.write(outfile = final_tree_dir / 'identity' / hgt[0] + '.genetree', \n",
    "                features=['accession', 'taxid'], format_root_node=False, format=1)\n",
    "        S.write(outfile = final_tree_dir / 'identity' / hgt[0] + '.speciestree', \n",
    "                format_root_node=False, format=9)\n",
    "    else:\n",
    "        raise RuntimeError('sth went terribly wrong!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cbab2652",
   "metadata": {},
   "source": [
    "## Initial analysis of tree properties   \n",
    "Used as a part of a manual verification of the results.   \n",
    "It's recommended to also take a look at the trees themselves, as well as partial results from all stages of the analysis.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "89fb5d83",
   "metadata": {},
   "source": [
    "Branch lengths:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f59de84a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# all branch lengths for trees with displaced clade criterion:\n",
    "dcl_blen = [l for bl, hgt in zip(all_branch_lengths, hgt_data[1:]) for l in bl if hgt[1] == 'hgt' ]\n",
    "# all branch lengths for well-supported HGTs:\n",
    "wsp_blen = [l for bl, hgt in zip(all_branch_lengths, hgt_data[1:]) for l in bl if hgt[2]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b40315d9",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,2))\n",
    "plt.subplot(121)\n",
    "plt.title('All displaced clades')\n",
    "plt.hist(dcl_blen, bins=80)\n",
    "plt.subplot(122)\n",
    "plt.title('Well-supported')\n",
    "plt.hist(wsp_blen, bins=80)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16c2f9ff",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Fungal clade supports for trees with displaced clade criterion:\n",
    "dcl_fgsup = [hgt[-3] for hgt in hgt_data[1:] if hgt[1] == 'hgt' ]\n",
    "# Fungal clade suports for well-supported HGTs:\n",
    "wsp_fgsup = [hgt[-3] for hgt in hgt_data[1:] if hgt[2] == 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eca29ceb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Local average supports for trees with displaced clade criterion:\n",
    "dcl_avsup = [hgt[-2] for hgt in hgt_data[1:] if hgt[1] == 'hgt' ]\n",
    "# Local average suports for well-supported HGTs:\n",
    "wsp_avsup = [hgt[-2] for hgt in hgt_data[1:] if hgt[2] == 'Yes']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "45beeadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(221)\n",
    "plt.title('All displaced clades, FG support')\n",
    "plt.hist(dcl_fgsup, bins=80)\n",
    "plt.subplot(222)\n",
    "plt.title('Well-supported, FG support')\n",
    "plt.hist(wsp_fgsup, bins=80)\n",
    "plt.subplot(223)\n",
    "plt.title('All displaced clades, LOC support')\n",
    "plt.hist(dcl_avsup, bins=80)\n",
    "plt.subplot(224)\n",
    "plt.title('Well-supported, LOC support')\n",
    "plt.hist(wsp_avsup, bins=80)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "48e11fcc",
   "metadata": {},
   "source": [
    "Reasons for lack of appropriate support of HGT hypothesis:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f55ade04",
   "metadata": {},
   "outputs": [],
   "source": [
    "clade_id = []\n",
    "for i, hgt in enumerate(hgt_data):\n",
    "    clade_id.append(sum(prhgt[0] == hgt[0] for prhgt in hgt_data[:i]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31c4bc59",
   "metadata": {},
   "outputs": [],
   "source": [
    "repositionable_problem = set([(hgt[0], clid) for hgt, clid in zip(hgt_data, clade_id) if hgt[1] == 'hgt' and hgt[-4] > 0])\n",
    "origin_problem = set([(hgt[0], clid) for hgt, clid in zip(hgt_data, clade_id) if hgt[1] == 'hgt' and hgt[4] == 'Undetermined'])\n",
    "# branch_length_problem = [hgt[0] for hgt in hgt_data if hgt[-1] >= 2]\n",
    "clade_support_problem = set([(hgt[0], clid) for hgt, clid in zip(hgt_data, clade_id) if hgt[1] == 'hgt' and hgt[-2] != 'N/A (leaf)' and int(hgt[-2]) < 90])\n",
    "homoplasy = set([(hgt[0], clid) for hgt, clid in zip(hgt_data, clade_id) if hgt[1] == 'homoplasy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf0d8522",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Problem with repositionable:', len(repositionable_problem))\n",
    "print('Problem with gene origin:', len(origin_problem))\n",
    "# print('Problem with branch length:', len(branch_length_problem))\n",
    "print('Problem with fungal clade support:', len(clade_support_problem))\n",
    "print('Homoplasy:', len(homoplasy))\n",
    "# print('Any problem:', len(repositionable_problem | origin_problem | branch_length_problem | clade_support_problem), 'out of', len(dcl_data))\n",
    "# print('Non-problem:', len(dcl_data) - len(repositionable_problem | origin_problem | branch_length_problem | clade_support_problem))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a0866004",
   "metadata": {},
   "outputs": [],
   "source": [
    "venn_data = {'Not repositionable' : repositionable_problem,\n",
    "             'Undeterminable donor': origin_problem, \n",
    "             'Low branch support': clade_support_problem}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d7bf1898",
   "metadata": {},
   "outputs": [],
   "source": [
    "from venn import venn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "40fff2c7",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "venn(venn_data)\n",
    "plt.show()\n",
    "plt.savefig('Results/%s_clade_problems.png' % CLUSTER_SUBDIR, dpi=600)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6383f19b",
   "metadata": {},
   "source": [
    "## Select a random set of trees for manual inspection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fadda996",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy.random as rd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "212cb99f",
   "metadata": {},
   "outputs": [],
   "source": [
    "well_supported_hgt_clusters = [hgt[0] for hgt in hgt_data[1:] if hgt[2]]\n",
    "len(well_supported_hgt_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "df114504",
   "metadata": {},
   "outputs": [],
   "source": [
    "randomly_selected_clusters = rd.choice(well_supported_hgt_clusters, 10)\n",
    "print(randomly_selected_clusters)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1b4ef0b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('cluster_list_for_manual_verification.txt', 'w') as h:\n",
    "    h.write('\\n'.join(randomly_selected_clusters) + '\\n')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
