{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "507b774d",
   "metadata": {},
   "source": [
    "## Description\n",
    "In this notebook, we analyze generate the query and analyze the results of contaminant screening blast.   \n",
    "We remove target proteins for which we didn't detect a fungal protein on the same contig.  \n",
    "A fungal protein is defined as a protein for which the first non-self blast hit is fungal.   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "815b9b47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "from ete3 import NCBITaxa\n",
    "from skbio.alignment import StripedSmithWaterman, local_pairwise_align_protein, local_pairwise_align_ssw\n",
    "from Bio.Align import substitution_matrices\n",
    "from Bio import pairwise2\n",
    "from path import Path\n",
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f0215622",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ffc89f6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "fungi_taxid = 4751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1fcd0c0f",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2scaffold_file = 'acc2scaffold.tsv'\n",
    "acc2scaffold = {}\n",
    "with open(acc2scaffold_file) as h:\n",
    "    for l in h:\n",
    "        l = l.strip().split('\\t')\n",
    "        assert l[0] not in acc2scaffold\n",
    "        acc2scaffold[l[0]] = l[1]\n",
    "len(acc2scaffold)  # note: with piromyces sp E2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ad2d568c",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_accessions = open('basal_accessions.txt')\n",
    "target_accessions = set(l.strip() for l in target_accessions if l.strip())\n",
    "len(target_accessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "77e3bcce",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_sequences_file = 'all_proteins.fa'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a2804d90",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid_table = open('final_homolog_taxid_table')\n",
    "taxid_table = {l.strip().split()[0]: l.strip().split()[1] for l in taxid_table if l.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aef57980",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2filename_file = 'acc2filename.txt'\n",
    "acc2filename = [l.strip().replace('.fa', '').split('\\t') for l in open(acc2filename_file) if l.strip()]\n",
    "acc2filename = {l[0]: l[1] for l in acc2filename}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4b7566d2",
   "metadata": {},
   "source": [
    "Input variables for section 1:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "941a2b0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "contaminant_blast_dir = Path('contaminant_filtering_blast/')\n",
    "input_cluster_directory = Path('first_round_clusters/')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "503841f2",
   "metadata": {},
   "source": [
    "Input variables for section 2:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3cca71fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "contaminant_blast_file = contaminant_blast_dir / 'blast_results'"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bf3ccbad",
   "metadata": {},
   "source": [
    "Output variable:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11135368",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cluster_directory = Path('first_round_filtered_clusters')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8296d78e",
   "metadata": {},
   "source": [
    "## Generating contaminant filtering blast query\n",
    "\n",
    "Here, for each remaining targer sequence, we'll take 10 random proteins from its conting.  \n",
    "They will be used as a query for BLASTp.   "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53943748",
   "metadata": {},
   "source": [
    "Step 1: Select target-fungal proteins from clusters and proteins from the same contigs  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9189584e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# WARNING: This will erase contents of contaminant_filtering_blast!\n",
    "# However, the processing in the next stage will still be valid, only inferred from \n",
    "# a different set of sequences.  \n",
    "fasta_dir = input_cluster_directory\n",
    "sequences_to_scan_dir = contaminant_blast_dir / 'sequences'\n",
    "print('Processing sequences in', fasta_dir)\n",
    "print('Output directory:', sequences_to_scan_dir)\n",
    "\n",
    "cluster_fasta_files = os.listdir(fasta_dir)\n",
    "print('Loaded %i clusters' % len(cluster_fasta_files))\n",
    "try:  # creating sub-directory\n",
    "    os.mkdir(sequences_to_scan_dir)\n",
    "except FileExistsError:\n",
    "    dir_contents = os.listdir(sequences_to_scan_dir)\n",
    "    for f in dir_contents:\n",
    "        os.remove(sequences_to_scan_dir + '/' + f)\n",
    "\n",
    "\n",
    "# Select target accessions from clusters with potential HGTs\n",
    "target_seqids_in_clusters = []\n",
    "for fstfl in cluster_fasta_files:\n",
    "    sequences = list(SeqIO.parse(fasta_dir / fstfl, 'fasta'))\n",
    "    tseqids = [s.id for s in sequences if s.id in target_accessions]\n",
    "    target_seqids_in_clusters.extend(tseqids)\n",
    "print('Selected %i target sequences' % len(target_seqids_in_clusters))\n",
    "# Select accessions of other proteins from the same scaffolds \n",
    "selected_scaffolds = list(set([acc2scaffold[acc] for acc in target_seqids_in_clusters]))\n",
    "print('Selected %i scaffolds' % len(selected_scaffolds))\n",
    "scaffold_taken_counts = Counter()  # nbs of proteins taken per scaffolds\n",
    "seqids_to_scan = set()  # accessions from neighbouring proteins in scaffolds, to be blasted against NR\n",
    "for acc in acc2scaffold:\n",
    "    if acc not in target_seqids_in_clusters:  # we don't want to scan potential HGTs\n",
    "        scf = acc2scaffold[acc]\n",
    "        if scf in selected_scaffolds:\n",
    "            if scaffold_taken_counts[scf] < 10:\n",
    "                scaffold_taken_counts[scf] += 1\n",
    "                seqids_to_scan.add(acc)\n",
    "assert all(acc in target_accessions for acc in seqids_to_scan)\n",
    "print('Selected %i sequences to scan' % len(seqids_to_scan))\n",
    "# Save the query sequences:\n",
    "sequences_to_write = []\n",
    "all_target_sequences = SeqIO.parse(target_sequences_file, 'fasta')\n",
    "for s in all_target_sequences:\n",
    "    if s.id in seqids_to_scan:\n",
    "        sequences_to_write.append(s)\n",
    "saved_seq_nb = 0\n",
    "for i in range(0, len(sequences_to_write), 100):\n",
    "    with open(sequences_to_scan_dir + '/chunk%i.fa' % i, 'w') as h:\n",
    "        saved_seq_nb += SeqIO.write(sequences_to_write[i:(i+100)], h, 'fasta')\n",
    "print('Saved', saved_seq_nb, 'contig neighbour sequences to scan')\n",
    "# with open(fasta_dir + '_to_scan.fa', 'w') as h:\n",
    "#     SeqIO.write(sequences_to_write, h, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b737af9d",
   "metadata": {},
   "source": [
    "*Now it's time to run BLASTp manually.* "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6e4357e7",
   "metadata": {},
   "source": [
    "## Detecting contaminants"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed81cd81",
   "metadata": {},
   "source": [
    "In this part, we analyze the resuts of blastp vs NR of proteins selected in the previous stage.   \n",
    "Do not run the previous section again! Just use this one.  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d73a7250",
   "metadata": {},
   "source": [
    "Parse the results of contaminant screening blast:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "93371254",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc2homolog_taxids = {}  # list of taxids of homologs sorted by increasing e-value\n",
    "blast_results = open(contaminant_blast_file)\n",
    "for l in blast_results:\n",
    "    l = l.strip().split('\\t')\n",
    "    if l[-1] == \"N/A\":  # Note: l[-1] == taxid; we're only interested in checking if the closest non-self hit is fungal\n",
    "        continue\n",
    "    try:\n",
    "        acc2homolog_taxids[l[0]].append((int(l[-1]), float(l[-2])))  # taxid and evalue\n",
    "    except KeyError:\n",
    "        acc2homolog_taxids[l[0]] = [(int(l[-1]), float(l[-2]))]\n",
    "print('Parsed blast results for', len(acc2homolog_taxids), 'query accessions')\n",
    "# For each target protein, sort its homologs according to the e-value\n",
    "for k in acc2homolog_taxids:\n",
    "    acc2homolog_taxids[k] = sorted(acc2homolog_taxids[k], key = lambda x: x[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cc2b870e",
   "metadata": {},
   "source": [
    "For each contig, obtain the ancestry score (= the number of proteins which have a fungal first hit, except host)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7319a83",
   "metadata": {},
   "outputs": [],
   "source": [
    "ancestry_scores = Counter()  \n",
    "i = 0\n",
    "for acc in acc2homolog_taxids:\n",
    "    tx_evalue_list = acc2homolog_taxids[acc]\n",
    "    query_taxid = tx_evalue_list[0][0] # assuming self is the closest hit\n",
    "    try:\n",
    "        first_hit_tx = next((tx for tx, ev in tx_evalue_list if tx != query_taxid))\n",
    "    except StopIteration:\n",
    "        continue\n",
    "    lineage = ncbi.get_lineage(first_hit_tx)\n",
    "    if fungi_taxid in lineage:\n",
    "        scaffold = acc2scaffold[acc]\n",
    "        ancestry_scores[scaffold] += 1\n",
    "print('Obtained scores for %i scaffolds' % len(ancestry_scores))\n",
    "print('%i scaffolds have a score greater than 1' % sum(ancestry_scores[scf] > 1 for scf in ancestry_scores))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "25a4fe43",
   "metadata": {},
   "source": [
    "Detect contaminants (= target proteins on scaffolds with no detected fungal protein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "51cadec7",
   "metadata": {},
   "outputs": [],
   "source": [
    "contaminant_seq_file = contaminant_blast_dir / 'identified_contaminants.fa'\n",
    "print('Input dir:', raw_cluster_dir)\n",
    "print('Output file:', contaminant_seq_file)\n",
    "cluster_fasta_files = os.listdir(input_cluster_directory)\n",
    "print('Loaded %i cluster fastas' % len(cluster_fasta_files))\n",
    "\n",
    "target_seqids_in_clusters = []\n",
    "for fstfl in cluster_fasta_files:\n",
    "    sequences = list(SeqIO.parse(input_cluster_directory  / fstfl, 'fasta'))\n",
    "    tseqids = [s.id for s in sequences if s.id in target_accessions]\n",
    "    target_seqids_in_clusters.extend(tseqids)\n",
    "print('Selected %i target sequences' % len(target_seqids_in_clusters))\n",
    "\n",
    "retained_sequence_nb_per_score = np.zeros(6, dtype='int')\n",
    "for acc in target_seqids_in_clusters:\n",
    "    scaffold = acc2scaffold[acc]\n",
    "    score = ancestry_scores[scaffold]\n",
    "    retained_sequence_nb_per_score[:(score+1)] += 1\n",
    "print('Score threshold vs number of retained sequences:')\n",
    "for i, snb in enumerate(retained_sequence_nb_per_score):\n",
    "    print(i, snb)\n",
    "    \n",
    "score_threshold = 1\n",
    "contaminant_seqids = set()\n",
    "for fstfl in cluster_fasta_files:\n",
    "    sequences = list(SeqIO.parse(input_cluster_directory / fstfl, 'fasta'))\n",
    "    for s in sequences:\n",
    "        if s.id in target_accessions:\n",
    "            scaffold = acc2scaffold[s.id]\n",
    "            score = ancestry_scores[scaffold]\n",
    "            if score < score_threshold:\n",
    "                contaminant_seqids.add(s.id)\n",
    "\n",
    "print('Detected %i potential contaminants' % len(contaminant_seqids))\n",
    "\n",
    "# target_sequences_file = 'all_proteins.fa'\n",
    "# contaminants = []\n",
    "# all_target_sequences = SeqIO.parse(target_sequences_file, 'fasta')\n",
    "# for seq in all_target_sequences:\n",
    "#     if seq.id in contaminant_seqids:\n",
    "#         contaminants.append(seq)\n",
    "# assert len(contaminants) == len(contaminant_seqids)\n",
    "# with open(contaminant_seq_file, 'w') as h:\n",
    "#     SeqIO.write(contaminants, h, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cb1c134",
   "metadata": {},
   "source": [
    "Save the identified contaminants:   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81ed2589",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('Results/contaminants_filter2.tsv', 'w') as h:\n",
    "    for sqid in contaminant_seqids:\n",
    "        h.write(sqid + '\\t' + acc2filename[sqid] + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a73ae1ea",
   "metadata": {},
   "source": [
    "Remove contaminants and save filtered clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1847a759",
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Input dir:', raw_cluster_dir)\n",
    "print('Output dir:', filtered_cluster_directory)\n",
    "\n",
    "try:\n",
    "    os.mkdir(filtered_cluster_directory)\n",
    "except FileExistsError:\n",
    "    dir_contents = os.listdir(filtered_cluster_directory)\n",
    "    for f in dir_contents:\n",
    "        os.remove(filtered_cluster_directory + '/' + f)\n",
    "\n",
    "print('Loaded %i cluster fastas' % len(cluster_fasta_files))\n",
    "removed_contaminants = []  # for testing purposes\n",
    "no_fungi_clusters = 0\n",
    "predominantly_fungal_clusters = 0\n",
    "large_fungal_clusters = 0\n",
    "saved_clusters = 0\n",
    "saved_sequences = 0\n",
    "saved_target_sequences = 0\n",
    "all_sequences_in_clusters = []\n",
    "for fstfl in cluster_fasta_files:\n",
    "    sequences = list(SeqIO.parse(input_cluster_directory, 'fasta'))\n",
    "    seqids_to_save = [s.id for s in sequences if s.id not in contaminant_seqids]\n",
    "    removed_contaminants += [s.id for s in sequences if s.id in contaminant_seqids]\n",
    "    # Check if contains any target sequences:\n",
    "    if not any(seqid in target_accessions for seqid in seqids_to_save):\n",
    "        no_fungi_clusters += 1\n",
    "        continue\n",
    "    # Check if ORFan\n",
    "    seqtx = set(int(taxid_table[sqid]) for sqid in seqids_to_save)\n",
    "    assert all(0 < tx for tx in seqtx)\n",
    "    seqlin = ncbi.get_lineage_translator(seqtx)\n",
    "    fungaltx = {tx for tx in seqlin if fungi_taxid in seqlin[tx]}\n",
    "    # fungal_sequences = [seqid for seqid in seqids_to_save if taxid_table[seqid] in fungaltx]\n",
    "    nbs_of_species = len(set(seqtx))\n",
    "    nbs_of_fungi = len(fungaltx)\n",
    "    if nbs_of_fungi >= 0.6*nbs_of_species :\n",
    "        predominantly_fungal_clusters += 1\n",
    "        continue\n",
    "#     elif len(fungal_sequences) > 20:\n",
    "#         large_fungal_clusters += 1\n",
    "#         continue\n",
    "        \n",
    "    sequences_to_save = [s for s in sequences if s.id in seqids_to_save]\n",
    "    all_sequences_in_clusters.extend(sequences_to_save)\n",
    "    assert sequences_to_save\n",
    "    with open(filtered_cluster_directory / fstfl, 'w') as h:\n",
    "        SeqIO.write(sequences_to_save, h, 'fasta')\n",
    "    saved_sequences += len(sequences_to_save)\n",
    "    saved_clusters += 1\n",
    "    saved_target_sequences += sum(s.id in target_accessions for s in sequences_to_save)\n",
    "print('After filtering:')\n",
    "print('Discarded %i contaminants' % len(contaminant_seqids))\n",
    "print('Discarded %i clusters without target sequences' % no_fungi_clusters)\n",
    "print('Discarded %i predominantly fungal clusters' % predominantly_fungal_clusters)\n",
    "# print('Discarded %i clusters with > 20 fungal sequences' % large_fungal_clusters)\n",
    "print('Saved %i out of %i clusters with %i sequences total, %i target sequences' % (saved_clusters, len(cluster_fasta_files), saved_sequences, saved_target_sequences))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "976b45e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered_cluster_files = os.listdir(filtered_cluster_directory)\n",
    "cluster_sizes = []\n",
    "for fstfl in filtered_cluster_files:\n",
    "    S = SeqIO.parse(filtered_cluster_directory + '/' + fstfl, 'fasta')\n",
    "    cluster_sizes.append(len(list(S)))\n",
    "print(fname + ':')\n",
    "print('Average cluster size:', sum(cluster_sizes)/len(cluster_sizes))\n",
    "print('Largest cluster sizes:', sorted(cluster_sizes)[-10:])\n",
    "print('Smallest cluster sizes:', sorted(cluster_sizes)[:10])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
