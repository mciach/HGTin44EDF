{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this notebook, we analyze results of clustering of sets of sequences on all stages of processing.\n",
    "We parse the results of clustering.  \n",
    "We discard ORFans and huge clusters.   \n",
    "We extract FASTAs and save them in `_raw_clusters` directories.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# %matplotlib notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from matplotlib import pyplot as plt\n",
    "import numpy as np\n",
    "import os\n",
    "from Bio import SeqIO\n",
    "from collections import Counter\n",
    "from ete3 import NCBITaxa\n",
    "from path import Path\n",
    "ncbi = NCBITaxa()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fungi_taxid = 4751"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid_table = open('final_homolog_taxid_table')\n",
    "taxid_table = {l.strip().split()[0]: l.strip().split()[1] for l in taxid_table if l.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_accessions = open('standardized_final_accessions')  \n",
    "all_accessions = {l.strip() for l in all_accessions if l.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target_accessions = open('basal_accessions.txt')\n",
    "target_accessions = set(l.strip() for l in target_accessions if l.strip())\n",
    "len(target_accessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "single_family_target_accessions = open('single_family_accessions.txt')\n",
    "single_family_target_accessions = set(l.strip() for l in single_family_target_accessions if l.strip())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster sanity checks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Check if each cluster contains self, if clusters are separate, and if clusters contain all accessions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Before running the following cells, run the code in the section titled *Function definitions* at the end of this notebook.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "algorithm='mcl'\n",
    "cluster_file = 'out.mcl_twoway_filter.mci.I17'\n",
    "output_dirname = 'first_round_clusters'\n",
    "min_number_of_species_in_cluster = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_table = {}\n",
    "cluster_table = parse_clustering(cluster_file, algorithm)   # need to substitute for proper algorithm\n",
    "occurences = Counter([acc for key in cluster_table for acc in cluster_table[key]])\n",
    "dups = [acc for acc in occurences if occurences[acc] > 1]\n",
    "cluster_sizes = [len(cluster_table[key]) for key in cluster_table]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Nb of accessions in multiple clusters in', input_fname, ':', len(dups))\n",
    "all_acc = {acc for key in cluster_table for acc in cluster_table[key]}\n",
    "print('Nb of accessions in all clusters:', len(all_acc))\n",
    "print('Nb of accessions in original sequence file:', len(all_accessions))\n",
    "print('Difference in nbs of accessions:', len(all_acc) - len(all_accessions))\n",
    "print('Nb of all clusters:', len(cluster_sizes))\n",
    "print('Nb of singleton clusters:', sum(x==1 for x in cluster_sizes))\n",
    "print('Nb of size <= 2 clusters:', sum(x<=2 for x in cluster_sizes))\n",
    "print(\"Nb of size >= 4 clusters:\", sum(x>=4 for x in cluster_sizes))\n",
    "print(\"Nb of size >= 300 clusters:\", sum(x>=300 for x in cluster_sizes))\n",
    "print('Nb of reasonable size clusters:', sum(4 <= x <= 300 for x in cluster_sizes))\n",
    "print('Average cluster size:', sum(cluster_sizes)/len(cluster_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(121)\n",
    "plt.hist(cluster_sizes, bins=40)\n",
    "plt.title('Distribution of cluster sizes')\n",
    "plt.subplot(122)\n",
    "plt.hist(np.log10(cluster_sizes), bins=40)\n",
    "plt.title('Log-size')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('Example large clusters:')\n",
    "print(sorted(cluster_table, key = lambda k: len(cluster_table[k]), reverse=True)[:10])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cluster filtering and selecting FASTAs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fasta_dir = output_dirname\n",
    "print('Input file:', cluster_file)\n",
    "print('Output directory:', fasta_dir)\n",
    "\n",
    "# try:\n",
    "#     os.mkdir(fasta_dir)\n",
    "# except FileExistsError:\n",
    "#     dir_contents = os.listdir(fasta_dir)\n",
    "#     for f in dir_contents:\n",
    "#         os.remove(fasta_dir + '/' + f)\n",
    "# remaining_sequences_file = 'unfiltered_sequences_for_alignment/' + '.'.join(fname.split('.')[:-1]) + '_joint.fasta'\n",
    "\n",
    "print(len(cluster_table), 'clusters to process')\n",
    "\n",
    "# Discard clusters without target proteins\n",
    "cluster_table = {k: cluster_table[k] for k in cluster_table if single_family_target_accessions & set(cluster_table[k])}\n",
    "print('Retained %i clusters with target proteins' % len(cluster_table))\n",
    "\n",
    "#cluster_table['7589']\n",
    "\n",
    "# get taxIDs to discard ORFans and purely fungal clusters\n",
    "# untranslated = 0\n",
    "all_remaining_seqids = [seqid for k in cluster_table for seqid in cluster_table[k]]\n",
    "all_remaining_taxids = set(int(taxid_table[seqid]) for seqid in all_remaining_seqids)\n",
    "all_lineages = {tx: ncbi.get_lineage(tx) for tx in all_remaining_taxids}  \n",
    "all_remaining_fungal_taxids = {tx for tx in all_remaining_taxids if fungi_taxid in all_lineages[tx]}\n",
    "all_fungal_lineage_ranks = ncbi.get_rank([lintx for fgtx in all_remaining_fungal_taxids for lintx in all_lineages[fgtx]]) \n",
    "\n",
    "\n",
    "nbs_of_species = {}\n",
    "nbs_of_fungi = {}\n",
    "nbs_of_fungal_groups = {}  # families or phyla, depending on the code below\n",
    "for k in cluster_table:\n",
    "    seqids = cluster_table[k]\n",
    "    seqtx = [int(taxid_table[sqid]) for sqid in seqids]\n",
    "    fungaltx = all_remaining_fungal_taxids & set(seqtx)\n",
    "    nbs_of_species[k] = len(set(seqtx))\n",
    "    nbs_of_fungi[k] = len(fungaltx)\n",
    "    # Inspecting phyla:\n",
    "    fungal_phyla = []\n",
    "    for fgtx in fungaltx:\n",
    "        current_phylum = None\n",
    "        for lintx in all_lineages[fgtx]:\n",
    "            if all_fungal_lineage_ranks[lintx] == 'phylum':\n",
    "                current_phylum = lintx\n",
    "                break\n",
    "        assert current_phylum is not None\n",
    "        fungal_phyla.append(current_phylum)\n",
    "    assert len(fungal_phyla) == len(fungaltx)\n",
    "    nbs_of_fungal_groups[k] = len(set(fungal_phyla))  # note: this ignores incertae sedis    \n",
    "    \n",
    "\n",
    "cluster_table = {k: cluster_table[k] for k in cluster_table if nbs_of_fungal_groups[k] <= 1}\n",
    "saved_query_proteins = sum(acc in target_accessions for k in cluster_table for acc in cluster_table[k])\n",
    "print('Retained %i clusters, %i target proteins, with a single fungal taxonomic group' % (len(cluster_table), saved_query_proteins))\n",
    "\n",
    "\n",
    "cluster_table = {k: cluster_table[k] for k in cluster_table if nbs_of_fungi[k] < 0.6*nbs_of_species[k]}\n",
    "saved_query_proteins = sum(acc in target_accessions for k in cluster_table for acc in cluster_table[k])\n",
    "print('Retained %i clusters, %i target proteins, with mostly non-fungal taxonomy' % (len(cluster_table), saved_query_proteins))\n",
    "\n",
    "\n",
    "cluster_table = {k: cluster_table[k] for k in cluster_table if nbs_of_species[k] >= min_number_of_species_in_cluster}\n",
    "saved_query_proteins = sum(acc in target_accessions for k in cluster_table for acc in cluster_table[k])\n",
    "print('Retained %i clusters, %i target proteins, with at least %i species' % (len(cluster_table), saved_query_proteins, min_number_of_species_in_cluster))\n",
    "\n",
    "\n",
    "print('Average final cluster size:', sum(len(cluster_table[k]) for k in cluster_table)/len(cluster_table))\n",
    "print('Largest cluster contains %i sequences' % max(len(cluster_table[k]) for k in cluster_table))\n",
    "print('Smallest cluster contains %i sequences' % min(len(cluster_table[k]) for k in cluster_table))\n",
    "acc_to_cluster = {acc:key for key in cluster_table for acc in cluster_table[key]}\n",
    "all_sequences = SeqIO.parse('standardized_final_sequences.fa', 'fasta')\n",
    "written_sequences = 0\n",
    "sequences_to_save = []\n",
    "for seq in all_sequences:\n",
    "    try:\n",
    "        cluster_id = acc_to_cluster[seq.id]\n",
    "    except KeyError:\n",
    "        continue\n",
    "    with open(fasta_dir / cluster_id + '.fa', 'a') as h:\n",
    "        SeqIO.write(seq, h, 'fasta')\n",
    "        written_sequences += 1\n",
    "print('Saved %i sequences' % written_sequences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_sizes = [len(cluster_table[key]) for key in cluster_table]\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(121)\n",
    "plt.hist(cluster_sizes, bins=40)\n",
    "plt.title('Distribution of cluster sizes')\n",
    "plt.subplot(122)\n",
    "plt.hist(np.log10(cluster_sizes), bins=40)\n",
    "plt.title('Log-size')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fungal_props_filtered = np.array([nbs_of_fungi[k]/nbs_of_species[k] for k in cluster_table])\n",
    "fungal_props_raw = np.array([nbs_of_fungi[k]/nbs_of_species[k] for k in nbs_of_fungi])\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(121)\n",
    "plt.title('Initial proportion of fungal taxa')\n",
    "plt.hist(fungal_props_raw[fungal_props_raw<1], bins=40)\n",
    "plt.subplot(122)\n",
    "plt.title('Final proportion of fungal taxa')\n",
    "plt.hist(fungal_props_filtered, bins=40)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Summarizing the clustering results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cluster_summary_file = output_dirname + '_summary.tsv'\n",
    "print('Saving summary in', cluster_summary_file)\n",
    "with open(cluster_summary_file, 'w') as h:\n",
    "    for k in cluster_table:\n",
    "        seqids = cluster_table[k]\n",
    "        seqtx = [int(taxid_table[sqid]) for sqid in seqids]\n",
    "        seqspec = ncbi.get_taxid_translator(seqtx)\n",
    "        fungaltx = set(seqtx) & all_remaining_fungal_taxids\n",
    "        for sid, stx in zip(seqids, seqtx):\n",
    "            h.write('\\t'.join(list(map(str, [k, sid, seqspec[stx], stx in fungaltx]))) + '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Function definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parsing cluster files:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_mmseqs2(cluster_file_path):\n",
    "    \"\"\"\n",
    "    Returns a dict indexed with cluster names,\n",
    "    storing lists of accessions in the cluster\n",
    "    \"\"\"\n",
    "    with open(cluster_file_path) as cluster_file:\n",
    "        cluster_table = {}\n",
    "        for l in cluster_file:\n",
    "            ref_id, mem_id = l.strip().split()\n",
    "            try:\n",
    "                cluster_table[ref_id].append(mem_id)\n",
    "            except KeyError:\n",
    "                cluster_table[ref_id] = [mem_id]\n",
    "    return cluster_table\n",
    "\n",
    "def parse_cdhit(cluster_file_path):\n",
    "    with open(cluster_file_path) as cluster_file:\n",
    "        cluster_table = {}\n",
    "        current_cluster = ''\n",
    "        for l in cluster_file:\n",
    "            if l[0] == '>':\n",
    "                current_cluster = l[1:].strip().replace(' ', '_')\n",
    "                cluster_table[current_cluster] = []\n",
    "            else:\n",
    "                l = l.strip().split()\n",
    "                acc = l[2][1:-3]\n",
    "                cluster_table[current_cluster].append(acc)\n",
    "    return cluster_table\n",
    "\n",
    "def parse_mcl(cluster_file_path):\n",
    "    with open(cluster_file_path) as cluster_file:\n",
    "        cluster_table = {}\n",
    "        for i, l in enumerate(cluster_file):\n",
    "            cluster_table[str(i)] = l.strip().split()\n",
    "    return cluster_table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def parse_clustering(cluster_file_path, algorithm):\n",
    "    if algorithm=='mmseqs2':\n",
    "        return parse_mmseqs2(cluster_file_path)\n",
    "    elif algorithm=='cd-hit':\n",
    "        return parse_cdhit(cluster_file_path)\n",
    "    elif algorithm=='mcl':\n",
    "        return parse_mcl(cluster_file_path)\n",
    "    else:\n",
    "        raise NotImplementedError()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
