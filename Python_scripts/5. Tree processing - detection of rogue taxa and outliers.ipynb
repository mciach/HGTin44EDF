{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d5622c91",
   "metadata": {},
   "source": [
    "## Description"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "830d9496",
   "metadata": {},
   "source": [
    "## Data & modules"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "96f19825",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import os\n",
    "from path import Path\n",
    "from ete3 import Tree\n",
    "from Bio import SeqIO\n",
    "from ete3 import NCBITaxa\n",
    "ncbi = NCBITaxa()\n",
    "from hgt_algorithms import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f60283ac",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_dir = Path('second_round_raw_trees/')\n",
    "input_fasta_file = 'out.mcl_twoway_filter.mci.I17.second_stage.fa'  \n",
    "output_tree_dir = Path('second_round_processed_trees')\n",
    "output_fasta_dir = Path('third_round_clusters')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "918cca3d",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_accessions = open('basal_accessions.txt')\n",
    "target_accessions = set(l.strip() for l in target_accessions if l.strip())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0795c991",
   "metadata": {},
   "outputs": [],
   "source": [
    "taxid_table = open('final_homolog_taxid_table')\n",
    "taxid_table = {l.strip().split()[0]: l.strip().split()[1] for l in taxid_table if l.strip()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2d5f7a1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "fungi_taxid = 4751"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b46c1410",
   "metadata": {},
   "source": [
    "## Selecting a neighbourhood of fungal proteins"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17e5fd2c",
   "metadata": {},
   "source": [
    "For each tree, we'll retain only those leaves that are closer than a given distance threshold (in sps) from any target protein. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0c3318e",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_neihbourhood_threshold = 3.33\n",
    "\n",
    "tree_files = [l for l in os.listdir(tree_dir) if 'treefile' in l]\n",
    "raw_tree_sizes = []\n",
    "raw_trees = []\n",
    "rogue_pruned_tree_sizes = []\n",
    "truncated_tree_sizes = []\n",
    "truncated_trees = []\n",
    "discarded_trees = []\n",
    "raw_diameters = []\n",
    "rogue_pruned_diameters = []\n",
    "truncated_diameters = []\n",
    "for fname in tree_files:\n",
    "    T = Tree(tree_dir/fname, format=1)  # treating support as internal node names to handle missing support values\n",
    "    T.set_outgroup(T.get_midpoint_outgroup())\n",
    "    T.filename = fname\n",
    "    raw_diameters.append(sum(c.get_farthest_leaf()[1] + c.dist for c in T.children))\n",
    "    raw_tree_sizes.append(len(T))\n",
    "    raw_trees.append(T.copy())\n",
    "    all_leaf_names = set([l.name for l in T])\n",
    "    non_rogue_names = all_leaf_names - consensus_rogues\n",
    "    ## Disabled rogue pruning cos we lose nice HGTs \n",
    "    # T.prune(non_rogue_names, preserve_branch_length=True)\n",
    "    target_in_T = set(l for l in T if l.name in target_accessions)\n",
    "    if not target_in_T:\n",
    "        discarded_trees.append(T)\n",
    "        continue\n",
    "    rogue_pruned_diameters.append(sum(c.get_farthest_leaf()[1] + c.dist for c in T.children))\n",
    "    rogue_pruned_tree_sizes.append(len(T))\n",
    "    min_distances_to_target = [min(T.get_distance(t, l) for t in target_in_T) for l in T]\n",
    "    target_neighbourhood = [t for d,t in zip(min_distances_to_target, T) if d <= sps_neihbourhood_threshold]\n",
    "    T.prune(target_neighbourhood, preserve_branch_length=True)\n",
    "    if len(T) >= 4:\n",
    "        truncated_tree_sizes.append(len(T))\n",
    "        truncated_trees.append(T)\n",
    "        truncated_diameters.append(sum(c.get_farthest_leaf()[1] + c.dist for c in T.children))\n",
    "    \n",
    "print('Processed %i trees, %i sequences, from' % (len(raw_tree_sizes), sum(raw_tree_sizes)), tree_dir)\n",
    "print('Retained %i trees (>=4 leaves) with target proteins after rogue removal' % len(rogue_pruned_tree_sizes))\n",
    "print('Retained %i trees, %i sequences, after truncating neighbourhood, smallest tree has %i leaves' % (len(truncated_tree_sizes), sum(truncated_tree_sizes), min(truncated_tree_sizes)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dc8312d1",
   "metadata": {},
   "source": [
    "Cells for a manual inspection of results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fb03510",
   "metadata": {},
   "outputs": [],
   "source": [
    "# discarded_filenames = set(tree_files) - set(T.filename for T in truncated_trees)\n",
    "# list(discarded_filenames)[:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab76f1e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = raw_trees[tree_files.index('663.fa.aln.treefile')]  \n",
    "# target_in_T = [l.name for l in T if l.name in target_accessions]\n",
    "# target_in_T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b0424a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# min_distances_to_target = [min(T.get_distance(t, l) for t in target_in_T) for l in T]\n",
    "# plt.figure()\n",
    "# plt.hist(min_distances_to_target, bins=40)\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47c664b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# retained_filenames = [T.filename for T in truncated_trees]\n",
    "# '453.fa.aln.treefile' in retained_filenames"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8001ae26",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = truncated_trees[truncated_tree_sizes.index(min(truncated_tree_sizes))]\n",
    "# print(T.filename)\n",
    "# set(l for l in T if l.name in target_accessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e3ad829",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = discarded_trees[0]\n",
    "# print(T.filename)\n",
    "# T = Tree(tree_dir/T.filename, format=1)\n",
    "# set(l for l in T if l.name in target_accessions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dd5f332f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# T = truncated_trees[retained_filenames.index('453.fa.aln.treefile')]\n",
    "# print(T.filename)\n",
    "# set(l for l in T if l.name in target_accessions)\n",
    "# print(T)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f11cd262",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(131)\n",
    "plt.title('Leaf count before cutting')\n",
    "plt.hist(raw_tree_sizes, bins=40)\n",
    "plt.subplot(132)\n",
    "plt.title('Leaf count after rogue removal')\n",
    "plt.hist(rogue_pruned_tree_sizes, bins=40)\n",
    "plt.subplot(133)\n",
    "plt.title('Leaf count after nhbd selection')\n",
    "plt.hist(truncated_tree_sizes, bins=40)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Largest tree size before cutting:', max(raw_tree_sizes))\n",
    "print('Largest tree size after cutting:', max(truncated_tree_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88a0dc7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(131)\n",
    "plt.title('Diameter before cutting')\n",
    "plt.hist(raw_diameters, bins=40)\n",
    "plt.subplot(132)\n",
    "plt.title('Diameter after rogue pruning')\n",
    "plt.hist(rogue_pruned_diameters, bins=40)\n",
    "plt.subplot(133)\n",
    "plt.title('Diameter after neighbourhood selection')\n",
    "plt.hist(truncated_diameters, bins=40)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Largest diameter of raw tree:', max(raw_diameters), 'cluster', tree_files[raw_diameters.index(max(raw_diameters))])\n",
    "print('Largest diameter after rogue pruning:', max(rogue_pruned_diameters))\n",
    "print('Largest diameter after nbhd selection:', max(truncated_diameters))\n",
    "print('Smallest diameter of a raw tree:', min(raw_diameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9429743",
   "metadata": {},
   "source": [
    "## Long branch cutting"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23e61502",
   "metadata": {},
   "source": [
    "For each tree, we'll iteratively remove the longest branch (thus cutting the tree into two trees) until all branches are shorter than a given threshold (in sps).  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "95c1553b",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_threshold = 1.598\n",
    "\n",
    "cut_trees = []\n",
    "cut_tree_sizes = []\n",
    "selected_cut_trees = []\n",
    "cut_diameters = []\n",
    "selected_diameters = []\n",
    "selected_tree_sizes = []\n",
    "for T in truncated_trees:\n",
    "    for i,n in enumerate(T.traverse('postorder')):\n",
    "        if not n.is_leaf():\n",
    "            n.name = str(i)  # labelling internal nodes for processing reasons\n",
    "    UT = UnrootedForest(T)\n",
    "    UT.disintegrate(sps_threshold)\n",
    "    F = UT.get_ete3()\n",
    "    F = [FT for FT in F if len(FT) >= 4]\n",
    "    for FT in F: FT.filename = T.filename\n",
    "    cut_trees.extend(F)\n",
    "    cut_diameters.extend([sum(c.get_farthest_leaf()[1] + c.dist for c in FT.children) for FT in F])\n",
    "    cut_tree_sizes.extend([len(FT) for FT in F])\n",
    "    for FT in F:\n",
    "        remaining_accessions = set([l.name for l in FT])\n",
    "        remaining_taxa = set([taxid_table[acc] for acc in remaining_accessions])\n",
    "        lineages = {tx: ncbi.get_lineage(tx) for tx in remaining_taxa}  \n",
    "        fungal_taxids = {tx for tx in remaining_taxa if fungi_taxid in lineages[tx]}\n",
    "        if fungal_taxids and len(remaining_taxa) >= len(fungal_taxids) + 3:\n",
    "            selected_cut_trees.append(FT)\n",
    "            selected_diameters.append(sum(c.get_farthest_leaf()[1] + c.dist for c in FT.children))\n",
    "            selected_tree_sizes.append(len(FT))\n",
    "    \n",
    "print('Processed %i trees' % len(truncated_trees))\n",
    "print('Obtained %i trees (>=4 leaves) after cutting long branches' % len(cut_trees))\n",
    "print('Obtained %i trees (>=4 leaves) with target proteins' % len(selected_cut_trees))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddba8446",
   "metadata": {},
   "source": [
    "Inspect the results:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4809feb6",
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(131)\n",
    "plt.title('Leaf count before cutting')\n",
    "plt.hist(raw_tree_sizes, bins=40)\n",
    "plt.subplot(132)\n",
    "plt.title('Leaf count after cutting')\n",
    "plt.hist(cut_tree_sizes, bins=40)\n",
    "plt.subplot(133)\n",
    "plt.title('Leaf count after selection')\n",
    "plt.hist(selected_tree_sizes, bins=40)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Largest tree size before cutting:', max(raw_tree_sizes))\n",
    "print('Largest tree size after cutting:', max(cut_tree_sizes))\n",
    "print('Largest cut tree with target proteins:', max(selected_tree_sizes))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "359dd77d",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(8,4))\n",
    "plt.subplot(131)\n",
    "plt.title('Diameter before cutting')\n",
    "plt.hist(truncated_diameters, bins=40)\n",
    "plt.subplot(132)\n",
    "plt.title('Diameter after cutting')\n",
    "plt.hist(cut_diameters, bins=40)\n",
    "plt.subplot(133)\n",
    "plt.title('Diameter after selecting targets')\n",
    "plt.hist(selected_diameters, bins=40)\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "print('Largest diameter before cutting:', max(truncated_diameters))\n",
    "print('Largest diameter after cutting:', max(cut_diameters))\n",
    "print('Largest diameter with target:', max(selected_diameters))\n",
    "print('Smallest diameter with target:', min(selected_diameters))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "092775fd",
   "metadata": {},
   "source": [
    "Check the minimal distance to any target protein for all leaves in an example tree:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "75f9cadc",
   "metadata": {},
   "outputs": [],
   "source": [
    "target_in_T = set(l for l in T if l.name in target_accessions)\n",
    "min_distances_to_target = [min(T.get_distance(t, l) for t in target_in_T) for l in T]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cce5a18",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure()\n",
    "plt.hist(min_distances_to_target, bins=40)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b0d022",
   "metadata": {},
   "outputs": [],
   "source": [
    "sum(d < 2.48 for d in min_distances_to_target)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "608b0a51",
   "metadata": {},
   "source": [
    "## Saving processed trees & cluster FASTAs"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c15e2e5",
   "metadata": {},
   "source": [
    "Create the output directory for processed trees; If it exists, erase its contents; Save the trees:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91fc50c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(output_tree_dir)\n",
    "except FileExistsError:\n",
    "    dir_contents = os.listdir(output_tree_dir)\n",
    "    for f in dir_contents:\n",
    "        os.remove(output_tree_dir + '/' + f)\n",
    "        \n",
    "for i, T in enumerate(selected_cut_trees):\n",
    "    T.write(outfile = output_tree_dir / '%i.treefile' % i, format = 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff6c3b6",
   "metadata": {},
   "source": [
    "Saving tree FASTAs for re-alignment:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e15d14bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "sequences = list(SeqIO.parse(joint_fasta_file, 'fasta'))\n",
    "sequences = {s.id: s for s in sequences}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a3707c56",
   "metadata": {},
   "source": [
    "Create the output directory for FASTAs of sequences in the processed trees; If it exists, erase its contents; Save the FASTAs:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a74ce3a",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "    os.mkdir(output_fasta_dir)\n",
    "except FileExistsError:\n",
    "    dir_contents = os.listdir(output_fasta_dir)\n",
    "    for f in dir_contents:\n",
    "        os.remove(output_fasta_dir + '/' + f)\n",
    "\n",
    "for i, T in enumerate(selected_cut_trees):\n",
    "    cluster = [sequences[l.name] for l in T]\n",
    "    with open(output_fasta_dir / 'Cluster_%i.fa' % i, 'w') as h:\n",
    "        SeqIO.write(cluster, h, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bdd0e6e3",
   "metadata": {},
   "source": [
    "## Alternative version - long leaf removal without internal branch cutting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c69733ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sps_threshold = 1.328\n",
    "# long_leaves = []\n",
    "# trees = os.listdir(tree_dir)\n",
    "# all_accessions_in_trees = []\n",
    "# for fname in trees:\n",
    "#     T = Tree(tree_dir/fname, format=1)  # treating support as internal node names to handle missing support values\n",
    "#     T.set_outgroup(T.get_midpoint_outgroup())\n",
    "#     all_accessions_in_trees.extend([l.name for l in T])\n",
    "#     for i,n in enumerate(T.traverse('postorder')):\n",
    "#         if not n.is_leaf():\n",
    "#             n.name = str(i)\n",
    "#     UT = UnrootedForest(T)\n",
    "#     UT.disintegrate(sps_threshold)\n",
    "#     F = UT.get_ete3()\n",
    "#     long_leaves.extend([tf.name for tf in F if len(tf) == 1])\n",
    "# assert len(long_leaves) == len(set(long_leaves))\n",
    "# assert len(all_accessions_in_trees) == len(set(all_accessions_in_trees))\n",
    "# long_leaves = set(long_leaves)\n",
    "# all_accessions_in_trees = set(all_accessions_in_trees)\n",
    "# print('Found', len(long_leaves), 'long leaves, including', len(target_accessions & long_leaves), 'target ones for sps threshold', sps_threshold)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fa03052f",
   "metadata": {},
   "source": [
    "Found 3914 long leaves, including 776 target ones for sps threshold 1.1158, full disintegration    \n",
    "Found 2623 long leaves, including 578 target ones for sps threshold 1.328, full disintegration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3d4410",
   "metadata": {},
   "outputs": [],
   "source": [
    "# remaining_accessions = all_accessions_in_trees - (ml_rogues | long_leaves)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cb142254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Long leaf and ML rogues:', len(ml_rogues & long_leaves))\n",
    "# print('Removed accessions:', len(ml_rogues | long_leaves), 'out of', len(all_accessions_in_trees))\n",
    "# print('Removed target accessions:', len((ml_rogues|long_leaves)&target_accessions), 'out of', len(all_accessions_in_trees & target_accessions))\n",
    "# print('Remaining accessions:', len(remaining_accessions))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "83044685",
   "metadata": {},
   "source": [
    "Saving remaining sequences for reclustering:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9565a051",
   "metadata": {},
   "outputs": [],
   "source": [
    "# raw_cluster_dir = 'first_round_clusters/' + CLUSTER_DIR\n",
    "# raw_cluster_files = os.listdir(raw_cluster_dir)\n",
    "# all_sequences = SeqIO.parse(main_sequence_file, 'fasta')\n",
    "# all_remaining_sequences = [] \n",
    "# for s in all_sequences:\n",
    "#     if s.id in remaining_accessions:\n",
    "#         all_remaining_sequences.append(s)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "65e42e1f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# print('Retrieved', len(all_remaining_sequences), 'sequences')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d249ce5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_cluster_dir = 'second_round_clusters/'\n",
    "# new_cluster_joint_fasta_file = new_cluster_dir + CLUSTER_DIR + '.fa'\n",
    "# with open(new_cluster_joint_fasta_file, 'w') as h:\n",
    "#     SeqIO.write(all_remaining_sequences, h, 'fasta')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41889655",
   "metadata": {},
   "source": [
    "## Optional: rogue taxon data parsing using RogueNaRok's results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "48e5c974",
   "metadata": {},
   "outputs": [],
   "source": [
    "# roguenarok_files = [f for f in os.listdir(tree_dir) if '_droppedRogues' in f]\n",
    "# ml_rogues = []\n",
    "# consensus_rogues = []\n",
    "# empty_result_files = []\n",
    "# for fname in roguenarok_files: \n",
    "#     if 'droppedRogues' in fname:\n",
    "#         rogues = open(tree_dir / fname).readlines()\n",
    "#         if not rogues:\n",
    "#             empty_result_files.append(fname)\n",
    "#             continue\n",
    "#         rogue_taxa = set()\n",
    "#         for l in rogues:\n",
    "#             l = l.strip().split('\\t')\n",
    "#             taxa =  l[2]\n",
    "#             if taxa not in {'NA', 'taxon'}:\n",
    "#                 taxa = taxa.split(',')\n",
    "#                 rogue_taxa.update(taxa)\n",
    "#         if 'MLtree' in fname:\n",
    "#             assert not rogue_taxa & set(ml_rogues)\n",
    "#             ml_rogues.extend(rogue_taxa)\n",
    "#         if 'ufboot_consensus' in fname:\n",
    "#             assert not rogue_taxa & set(consensus_rogues)\n",
    "#             consensus_rogues.extend(rogue_taxa)\n",
    "# ml_rogues = set(ml_rogues)\n",
    "# consensus_rogues = set(consensus_rogues)\n",
    "# print('Found', len(ml_rogues), 'ML rogues, including', len(ml_rogues & target_accessions), 'target, and', len(consensus_rogues), 'consensus rogues, including', len(consensus_rogues & target_accessions), 'targets')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c2843f91",
   "metadata": {},
   "source": [
    "## SPS value testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829eb226",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_to_identity(2.11)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add3c5bf",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_to_sps(0.3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "137003a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_to_sps(0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b32adc9",
   "metadata": {},
   "outputs": [],
   "source": [
    "idv_std(3, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b5ce801a",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps = 1.1158\n",
    "sps_to_identity(sps) - idv_std(sps, 300)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2e61c8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_to_sps(sps_to_identity(0.8))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b57c9c72",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_to_identity(identity_to_sps(0.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "aafb326f",
   "metadata": {},
   "outputs": [],
   "source": [
    "sps_values = np.linspace(0, 5)\n",
    "id_values = sps_to_identity(sps_values)\n",
    "id_stds = idv_std(sps_values)\n",
    "plt.figure()\n",
    "plt.plot(sps_values, id_values)\n",
    "plt.plot(sps_values, id_values + id_stds)\n",
    "plt.plot(sps_values, id_values - id_stds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47be94fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
